
<h2>link de Dashboard</h2>
<div style="text-align: center;">
    <a href="https://app.dataquest.io/profile/230110330">LINK</a>
  </div>


<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Probabilidad y Estadística</title>

</head> 
<body>
<h1>Probabilidad y Estadística</h1>
<h2>"Tecnológico Nacional de México Campus Occidente del Estado de Hidalgo"</h2>

<h2>Datos Generales de la asignatura</h2>
<p>Nombre de la asignatura: <strong>Probabilidad y Estadística</strong></p>
<p>Nombre del alumno : <strong>Marco Antonio Mendoza Calva</strong></p>
<p>Carrera: <strong>Ingeniería en Tecnologías de la Información y Comunicaciones.</strong></p>



<body>
    <h1>Temario </h1>
   
        <ul>
   
   
            <h3>TEMA 1</h3>
   <ul>
               <li>1.1 Conceptos básicos de estadística</li>
               <li>1.2 Descripción de datos</li>
               <li>1.3 Medidas de tendencia central</li>
               <li>1.4 Parámetros para datos agrupados</li>
               <li>1.5 Distribución de frecuencias</li>
               <li>1.6 Técnicas de agrupación de datos</li>
               <li>1.7 Técnicas de muestreo</li>
               <li>1.8 Histogramas</li>
           </ul>
       </li>
       <h3>Subtemas</h1>
        <ul>
 <strong>1.1 Conceptos básicos de estadística</strong>
 <strong></strong>
    
 <li><strong>Definición Teoría de decisión:</strong></li>

    <p>es un enfoque que busca proporcionar un marco para la toma de decisiones en situaciones de incertidumbre. Esta teoría se basa en la idea de que las decisiones se toman en función de la información disponible y las posibles consecuencias de cada opción</p>
       
    <li><strong>Definición población:</strong></li>

    <p>la población se refiere al conjunto total de elementos o individuos que comparten características similares y que son objeto de estudio en un análisis estadístico. Esta población puede ser cualquier grupo de interés, como personas, objetos, eventos, u otras entidades que comparten ciertas propiedades que se desean estudiar.</p>
    <li><strong>Definición Teoría de decisión:</strong></li>

    <p>se refiere a un proceso que permite seleccionar una muestra de una población de forma aleatoria, donde cada individuo tiene la misma probabilidad de ser elegido. Este método se utiliza para obtener datos representativos de la población y así poder realizar análisis estadísticos más precisos.</p>
    <li><strong>Definición Parámetros aleatorios.:</strong></li>
    <p>se refieren a las características o propiedades que varían de forma aleatoria en una población. Estos parámetros pueden ser variables como la edad, altura, peso, ingresos, entre otros, que pueden ser medidos o cuantificados en cada individuo de la población.</p>
 </ul>
<ul>









    <strong>1.2 Descripción de datos</strong>
    <strong></strong>
    
 <li><strong>Datos agrupados y no agrupados:</strong></li>

    <p>Datos no agrupados: Datos individuales sin agrupar en clases o categorías.
        Datos agrupados: Datos organizados en clases o intervalos, con una frecuencia asociada a cada clase.</p>
       
    <li><strong> Frecuencia de clase:</strong></li>

    <p>La frecuencia de clase es el número de observaciones que caen en cada clase o intervalo de un conjunto de datos agrupados.</p>
    <li><strong>Frecuencia relativa:</strong></li>

    <p>La frecuencia relativa es la proporción de observaciones que caen en cada clase o intervalo con respecto al total de observaciones.</p>
    <li><strong>Punto medio:</strong></li>
    <p>El punto medio de una clase o intervalo es el valor que se encuentra justo en el centro del intervalo, es decir, la media aritmética de los límites inferior y superior de la clase.</p>

    <li><strong> Límites:</strong></li>
    <p>Los límites de una clase o intervalo son los valores que definen los extremos del intervalo. Cada clase tiene un límite inferior y un límite superior.</p>
    
    
    
</ul>
<ul><strong>1.3 Medidas de tendencia central:</strong>
    <strong></strong>
    
 

 <li><strong> Media aritmética:</strong>
  
</li> <p>Es el promedio o valor central de un conjunto de datos, se calcula sumando todos los valores y dividiéndolos entre el número total de datos.</p> 

 <li><strong>  Media geométrica:</strong></li> <p>Es una medida de tendencia central que se utiliza cuando se trabaja con datos en escala logarítmica, se calcula como la raíz enésima del producto de todos los valores.</p> 

<li><strong>  Media ponderada: </strong></li><p>Es una media en la que se asigna un peso o importancia diferente a cada valor, dependiendo de su relevancia o significado dentro del conjunto de datos.</p> 

 <li><strong> Mediana:</strong></li> <p>Es el valor central de un conjunto de datos ordenados de menor a mayor, que divide al conjunto en dos partes iguales.</p> 

 <li><strong> Moda:</strong></li> <p> Es el valor que aparece con mayor frecuencia en un conjunto de datos.</p> 
       
 <li><strong> Varianza:</strong></li> <p>  Mide cuánto se dispersan los valores de un conjunto de datos con respecto a la media. Se calcula como el promedio de los cuadrados de las desviaciones respecto a la media.</p> 

 <li><strong> Desviación estándar:</strong></li> <p>  Es la raíz cuadrada de la varianza y representa cuánto se desvían en promedio los valores del conjunto de datos con respecto a la media.</p> 

 <li><strong>Desviación media:</strong></li> <p>  Es el promedio de las diferencias absolutas entre cada valor y la media del conjunto de datos.</p>
 
 <li><strong>Desviación mediana:</strong></li> <p>  Es el promedio de las diferencias absolutas entre cada valor y la mediana del conjunto de datos.</p>
 
 <li><strong>Rango:</strong></li> <p>  Es la diferencia entre el valor máximo y el valor mínimo de un conjunto de datos.</p> 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 <ul><strong>1.4 Parámetros para datos agrupados:</strong>
    <strong></strong>
    
 
  
</li> <p>Los parámetros para datos agrupados se refieren a las medidas estadísticas que se calculan cuando los datos se presentan en forma de intervalos o grupos, en lugar de valores individuales. Estos parámetros incluyen la media, la mediana, la moda, la desviación estándar, entre otros, y permiten resumir y describir las características de un conjunto de datos agrupados.</p> 
</ul>
<ul><strong>1.5 Distribución de frecuencias:</strong>
    <strong></strong>
    
 
  
</li> <p> La distribución de frecuencias es una representación organizada de los datos, donde se muestra la cantidad de veces que cada valor o rango de valores aparece en un conjunto de datos. Esto permite visualizar la forma en que se distribuyen los datos y facilita el análisis y la interpretación de los mismos.</p> 
</ul>
<ul><strong>1.6 Técnicas de agrupación de datos:</strong>
    <strong></strong>
    
 
  
</li> <p>Las técnicas de agrupación de datos se refieren a los métodos utilizados para agrupar o clasificar los datos en categorías o intervalos. Esto incluye la determinación del número de grupos, el tamaño de los intervalos y la elección de los puntos de corte adecuados. La agrupación de datos es fundamental para la presentación y el análisis de datos.</p> 
</ul>
<ul><strong>1.7 Técnicas de muestreo:</strong>
    <strong></strong>
 <button onclick="window.location.href='TablaFrecuencias.html'" style="color: black;">Ejercicios tema 1</button>










    <body>
       
        <h2> Fundamentos de la Teoría de  Probabilidad.</h2>
       
            <ul>
       
       
                <h3>TEMA 2</h3>
       <ul>
                   <li>2.1 Técnicas de Conteo</li>
                   <li>2.1.1 Principio aditivo</li>
                   <li>2.1.2 Principio multiplicativo. </li>
                   <li>2.1.3 Notación Factorial.</li>
                   <li>2.1.4 Permutaciones.</li>
                   <li>2.1.5 Combinaciones. </li>
                   <li>2.1.6 Diagrama de Árbol.</li>
                   <li>2.1.7 Teorema del Binomio</li>
                   <li>2.2 Teoría elemental de probabilidad</li>
                   <li>2.3 Probabilidad de Eventos: Definición de espacio
                    muestral, definición de evento, simbología, unión,
                    intersección, diagramas de Venn</li>
                   <li>2.4 Probabilidad con Técnicas de Conteo: Axiomas,Teoremas</li>
                   <li>2.5 Probabilidad condicional: Dependiente,
                    Independiente.</li>
                   <li>2.6 Ley multiplicativa</li>
                   <li>2.7 Eventos independientes: Regla de Bayes</li>
                   
                   
               </ul>
           </li>
           <h3>Subtemas</h1>
            <ul>
                
     <strong>2.1 Técnicas de Conteo</strong>
     <strong></strong>
        
     <li><strong>2.1.1 Principio aditivo:</strong></li>
    
        <p> El principio aditivo establece que si un evento A y un evento B son mutuamente excluyentes, entonces la probabilidad de que ocurra A o B es igual a la suma de sus probabilidades individuales.</p>

        <li><strong> 2.1.2 Principio multiplicativo:</strong></li>
    
        <p> El principio multiplicativo establece que si dos eventos son independientes, entonces la probabilidad de que ambos ocurran es igual al producto de sus probabilidades individuales.</p>

        <li><strong> 2.1.3 Notación Factorial:</strong></li>
    
        <p> La notación factorial se utiliza para representar el número de formas en que se pueden ordenar n elementos. Se denota como n! y se lee "n factorial".</p>

        <li><strong> 2.1.4 Permutaciones:</strong></li>
    
        <p> Las permutaciones representan el número de formas en que se pueden ordenar r elementos de un conjunto de n elementos. Se calcula como n! / (n-r)!.</p>

        <li><strong> 2.1.5 Combinaciones:</strong></li>
    
        <p> Las combinaciones representan el número de formas en que se pueden seleccionar r elementos de un conjunto de n elementos, sin importar el orden. Se calcula como n! / (r! * (n-r)!).</p>

        <li><strong> 2.1.6 Diagrama de Árbol:</strong></li>
    
        <p> El diagrama de árbol es una representación gráfica que muestra todas las posibles secuencias de eventos en un experimento aleatorio. Ayuda a visualizar y calcular probabilidades.</p>

        <li><strong> 2.1.7 Teorema del Binomio:</strong></li>
    
        <p> El teorema del binomio establece una fórmula para calcular los coeficientes binomiales, que representan el número de formas de seleccionar k elementos de un conjunto de n elementos. Estos coeficientes se denotan como "n sobre k" o "nCk".</p>

        
        <strong>2.2 Teoría elemental de probabilidad:</strong>
        <strong></strong>
    
        <li><strong> Espacio muestral (Ω):</strong></li>
    
        <p>  Es el conjunto de todos los posibles resultados o sucesos de un experimento aleatorio.</p>

        <li><strong> Evento (A): </strong></li>
    
        <p> Es cualquier subconjunto del espacio muestral. Representa un conjunto de resultados que pueden ocurrir en un experimento.</p>

        <li><strong> Probabilidad (P): </strong></li>
    
        <p>  Es una medida que cuantifica la posibilidad de que ocurra un evento determinado. La probabilidad se expresa en un rango de valores entre 0 y 1, donde 0 indica que el evento es imposible y 1 indica que el evento es seguro.</p>
        

<strong>2.3 Probabilidad de Eventos:</strong>
        <strong></strong>

        <li><strong> Espacio muestral: </strong></li>
    
        <p>  El espacio muestral (Ω) es el conjunto de todos los posibles resultados o sucesos de un experimento aleatorio.</p>

        <li><strong>  Evento: </strong></li>
    
        <p>  Un evento (A) es un subconjunto del espacio muestral que representa un resultado o conjunto de resultados de interés en un experimento aleatorio.</p>


        <li><strong>  Simbología: </strong></li>
    
        <p> Los eventos se representan generalmente con letras mayúsculas (A, B, C, etc.).</p> 
        <p>  El espacio muestral se representa comúnmente con la letra Ω.</p>

        <li><strong>  Unión de eventos: </strong></li>
    
        <p>  La unión de dos eventos A y B, denotada como A ∪ B, es el evento que ocurre cuando ocurre al menos uno de los dos eventos.</p> 

        <li><strong>  Intersección de eventos: </strong></li>
    
        <p>   La intersección de dos eventos A y B, denotada como A ∩ B, es el evento que ocurre cuando ocurren ambos eventos simultáneamente.</p> 

        <li><strong>  Diagramas de Venn:</strong></li>
    
        <p> Los diagramas de Venn son representaciones gráficas que ilustran las relaciones entre diferentes eventos o conjuntos dentro del espacio muestral.</p> 







        <strong>2.4 Probabilidad con Técnicas de Conteo: Axiomas,
            Teoremas</strong>
     <strong></strong>

     <li><strong> Probabilidad con Técnicas de Conteo "Axiomas":</strong></li>
    
        <p> 
        <p>  Los axiomas de probabilidad establecen los principios básicos que debe cumplir una función de probabilidad. </p> 
        <p> La probabilidad de cualquier evento es un número no negativo.</p> 
        <p> La probabilidad del espacio muestral (el conjunto de todos los posibles resultados) es igual a 1.</p> 
        <p> La probabilidad de la unión de eventos mutuamente excluyentes es la suma de sus probabilidades individuales.</p> 



    <li><strong>Probabilidad con Técnicas de Conteo" Teoremas":</strong></li>
    
    
      <p>  Algunos teoremas importantes en probabilidad con técnicas de conteo son:</p> 
      <p>  Teorema de la Unión: La probabilidad de la unión de dos eventos A y B se calcula como P(A ∪ B) = P(A) + P(B) - P(A ∩ B).</p> 
      <p>  Teorema de la Intersección: La probabilidad de la intersección de dos eventos A y B se calcula como P(A ∩ B) = P(A) × P(B|A), donde P(B|A) es la probabilidad de B dado A.</p> 
      <p>  Teorema de la Probabilidad Condicional: La probabilidad de B dado A se calcula como P(B|A) = P(A ∩ B) / P(A). </p> 

      <strong>2.5 Probabilidad condicional: Dependiente,
        Independiente.</strong>
 <strong></strong>


 <li><strong>Probabilidad Condicional Eventos Dependientes:</strong></li>
    
    
 <p> 
    Cuando la probabilidad de un evento B depende de que ocurra otro evento A, se dice que los eventos son dependientes.
    La probabilidad condicional de B dado A se denota como P(B|A) y se calcula como:
    P(B|A) = P(A ∩ B) / P(A)
    En eventos dependientes, P(B|A) ≠ P(B), es decir, la probabilidad de B cambia si se conoce que ocurrió A.</p> 


    <li><strong> Probabilidad Condicional Eventos Independientes:</strong></li>
    
    
    <p>
        Cuando la probabilidad de un evento B no depende de que ocurra otro evento A, se dice que los eventos son independientes.
        Para eventos independientes, la probabilidad condicional de B dado A es igual a la probabilidad marginal de B:
        P(B|A) = P(B)
        En eventos independientes, P(B|A) = P(B), es decir, la probabilidad de B no cambia si se conoce que ocurrió A.</p> 


        <strong>2.6 Ley multiplicativa.</strong>
     <strong></strong>
    </ul>

    <p>Ley Multiplicativa:

        La Ley Multiplicativa establece que, para dos eventos A y B, la probabilidad de la intersección de A y B se calcula como:
        
        <p>P(A ∩ B) = P(A) × P(B|A)</p>
        
        Donde:
        
        <p>P(A) es la probabilidad del evento A.</p>
        <p>P(B|A) es la probabilidad condicional del evento B dado que el evento A ha ocurrido.</p>
        Esta ley se cumple tanto para eventos dependientes como independientes. En el caso de eventos independientes, la probabilidad condicional P(B|A) es igual a la probabilidad marginal P(B), por lo que la fórmula se simplifica a:
        
       <p> P(A ∩ B) = P(A) × P(B)</p>
        
        La Ley Multiplicativa es una herramienta fundamental para calcular probabilidades de la intersección de dos o más eventos, ya sea que estos sean dependientes o independientes.</p>


        <strong>2.7 Eventos independientes: Regla de Bayes.</strong>
        <strong></strong>

        <p>La Regla de Bayes es un teorema fundamental en probabilidad que permite calcular la probabilidad condicional inversa, es decir, la probabilidad de un evento A dado que ocurrió un evento B.

            La fórmula de la Regla de Bayes para eventos independientes es:
            
            <p>P(A|B) = (P(B|A) × P(A)) / P(B)</p>
            
            Donde:
            
           <p> P(A|B) es la probabilidad condicional de A dado B.</p>
            <p>P(B|A) es la probabilidad condicional de B dado A.</p>
           <p>P(A) es la probabilidad a priori del evento A.</p>
            <p>P(B) es la probabilidad a priori del evento B.</p>
           <p> La Regla de Bayes es muy útil cuando se tiene información sobre la probabilidad condicional en una dirección (P(B|A)) y se quiere calcular la probabilidad condicional en la dirección opuesta (P(A|B)).</p>
           <button onclick="window.location.href='Ejercicios.html'" style="color: black;">Ejercicios del 9 al 17</button>
           <h2>  Variables Aleatorias</h2>
           
           <ul>
           <h3>TEMA 3</h3>
           <ul>
                       <li>3.1 Variables aleatorias discretas:</li>
                       <li>3.1.1 Distribución de probabilidad en forma
                        general.</li>
                       <li>3.1.2 Valor esperado </li>
                       <li>3.1.3 Variancia, desviación estándar</li>
                       <li>3.1.4 Función acumulada.</li>
                       <li>3.2 Variables aleatorias Continuas </li>
                       <li>3.2.1Distribución de probabilidad en forma general                    </li>
                       <li>3.2.2 Valor esperado</li>
                       <li>3.2.3 Variancia, desviación estándar.</li>
                       <li>3.2.4 Función acumulada.</li>
                       <li>3.2.5 Cálculos de probabilidad.</li>
                       
                       
                       
                   </ul>
               </li>
               <h3>Subtemas</h1>
                <ul>
         <strong>3.1 Variables aleatorias discretas:        </strong>
         <strong></strong>
            
         <li><strong>3.1.1 Distribución de probabilidad en forma
            general</strong></li>

            <strong>Distribución de probabilidad en forma general</strong>
            <strong></strong>
    
            <p>La distribución de probabilidad es una función matemática que describe la probabilidad de que una variable aleatoria tome diferentes valores dentro de un rango determinado. Proporciona una representación completa de la probabilidad asociada con todos los posibles valores de la variable.</p>


            <strong>3.1.2 Valor esperado:</strong>
            <strong></strong>
    
            <p>El valor esperado, también conocido como media o esperanza matemática, es un concepto estadístico que representa el valor promedio que se espera que tome una variable aleatoria. Es una medida de tendencia central que resume la distribución de probabilidad de la variable.</p>


            <strong>3.1.3 Variancia, desviación estándar:</strong>
            <strong></strong>
    
            <p>La variancia es una medida de dispersión que indica cuánto se desvían, en promedio, los valores de una variable aleatoria respecto a su valor esperado. La desviación estándar es la raíz cuadrada de la variancia y representa el grado promedio de dispersión o variabilidad de los datos.</p>

            <strong>3.1.4 Función acumulada:</strong>
            <strong></strong>
    
            <p>La función de distribución acumulada, también llamada función de probabilidad acumulada, es una función matemática que describe la probabilidad de que una variable aleatoria tome un valor menor o igual a un valor específico. Proporciona información sobre la probabilidad acumulada de la variable a lo largo de todo su rango de valores.</p>



            <strong>3.2 Variables aleatorias Continuas  </strong>
            <strong></strong>

            <strong>3.2.1 Distribución de probabilidad en forma general:</strong>
            <strong></strong>
    
            <p>
                En el caso de variables aleatorias continuas, la distribución de probabilidad se describe mediante una función de densidad de probabilidad. Esta función especifica la probabilidad de que la variable aleatoria tome un valor particular dentro de un intervalo dado.</p>

                <strong>3.2.2 Valor esperado:</strong>
            <strong></strong>
    
            <p>
El valor esperado de una variable aleatoria continua se calcula integrando el producto del valor de la variable y su función de densidad de probabilidad sobre todo el rango de la variable. Representa el valor promedio que se espera que tome la variable.</p>

<strong>3.2.3 Variancia, desviación estándar:</strong>
<strong></strong>

<p>
    La variancia de una variable aleatoria continua se calcula integrando el cuadrado de la diferencia entre el valor de la variable y su valor esperado, ponderado por la función de densidad de probabilidad. La desviación estándar es la raíz cuadrada de la variancia.</p>

    <strong>3.2.4 Función acumulada:
</strong>

<p>
    La función de distribución acumulada de una variable aleatoria continua se define como la integral de la función de densidad de probabilidad desde menos infinito hasta el valor de la variable. Representa la probabilidad de que la variable aleatoria tome un valor menor o igual a un valor específico.</p>

    <strong>3.2.5 Cálculos de probabilidad:</strong>
<strong></strong>

<p>
    Para calcular probabilidades con variables aleatorias continuas, se utilizan las propiedades de la función de densidad de probabilidad y la función de distribución acumulada. Esto permite determinar la probabilidad de que la variable aleatoria tome un valor dentro de un intervalo específico.</p>





    <h2>Variables Aleatorias Discretas</h2>

    <iframe src="https://drive.google.com/file/d/1TjNpMiIYZfcJgbyjPV5ah0-ZjGyPUno_/preview" width="640" height="480" allow="autoplay"></iframe>


    <h2>Variables Aleatorias Continuas</h2>

    <iframe src="https://drive.google.com/file/d/1msuniNCXjI2kqQ7qFm6Hjr6jxOeb6v1e/preview" width="640" height="480" allow="autoplay"></iframe>


    <h2>Distribuciones de Probabilidad.</h2>
    <ul>
        <h3>TEMA 4</h3>
        <ul>
                    <li>4.1 Función de probabilidad.</li>
                    
                    <li>4.2 Distribución binomial.</li>
                    <li>4.3 Distribución hipergeométrica. </li>
                    <li>4.4 Distribución de Poisson.</li>
                    <li>4.5 Distribución normal</li>
                    <li>4.6 Distribución T-student </li>
                    <li>4.7 Distribución Chi cuadrada</li>
                    <li>4.8 Distribución F.  </li>
                    
                    
                    
                </ul>
            </li>
            <h3>Subtemas</h1>
             <ul>
      <strong>4.1 Función de probabilidad  </strong>

      <strong></strong>

      <p>La función de probabilidad, denotada como P(x), describe la probabilidad de que una variable aleatoria discreta X tome un valor específico x. La suma de todas las probabilidades de los posibles valores de X debe ser igual a 1.</p>

      <strong> 4.2 Distribución binomial:</strong>
      

      <strong></strong>

      <p>La distribución binomial modela la probabilidad de obtener x éxitos en n ensayos independientes, donde cada ensayo tiene solo dos posibles resultados (éxito o fracaso) y la probabilidad de éxito, p, es constante. La fórmula de la función de probabilidad binomial es: P(X=x) = nCx * p^x * (1-p)^(n-x), donde nCx representa la combinación de n elementos tomados de x en x.</p>

      <strong> 4.3 Distribución hipergeométrica:</strong>
      

      <strong></strong>

      <p>La distribución hipergeométrica describe la probabilidad de obtener x éxitos en un muestreo aleatorio sin reemplazo de una población finita de N elementos, donde hay K elementos de éxito y (N-K) elementos de fracaso. La fórmula de la función de probabilidad hipergeométrica es: P(X=x) = (KCx) * ((N-K)C(n-x)) / (NCn).</p>

      <strong> 4.4 Distribución de Poisson:</strong>
      

      <strong></strong>

      <p>La distribución de Poisson modela la probabilidad de que ocurran x eventos independientes en un intervalo de tiempo o espacio fijo, cuando el promedio de ocurrencia de estos eventos, λ, es conocido. La función de probabilidad de Poisson es: P(X=x) = e^(-λ) * λ^x / x!.</p>

      <strong> 4.5 Distribución normal:</strong>
      

      <strong></strong>

      <p>La distribución normal, también conocida como distribución gaussiana, se caracteriza por dos parámetros: la media (μ) y la desviación estándar (σ). La función de densidad de probabilidad normal es: f(x) = (1 / (σ * √(2π))) * e^(-(x-μ)^2 / (2σ^2)).</p>

      <strong> 4.6 Distribución T-student:</strong>
      

      <strong></strong>

      <p>La distribución T-student se utiliza cuando la desviación estándar de la población es desconocida y se debe estimar a partir de una muestra. La función de densidad de probabilidad T-student depende del grado de libertad, ν, y se denota como: f(t) = Γ((ν+1)/2) / (√(νπ) * Γ(ν/2)) * (1 + t^2/ν)^(-(ν+1)/2)..</p>

      <strong>4.7 Distribución Chi cuadrada:</strong>
      

      <strong></strong>

      <p>La distribución Chi cuadrada se utiliza para modelar la suma de los cuadrados de variables aleatorias independientes que siguen una distribución normal estándar. La función de densidad de probabilidad Chi cuadrada depende del número de grados de libertad, ν, y se denota como: f(x) = (1 / (2^(ν/2) * Γ(ν/2))) * x^(ν/2-1) * e^(-x/2), para x > 0.</p>

      <strong>4.8 Distribución F:</strong>
      

      <strong></strong>

      <p>La distribución F se utiliza para modelar el cociente de dos variables aleatorias independientes que siguen una distribución Chi cuadrada. La función de densidad de probabilidad F depende de los grados de libertad del numerador, ν1, y los grados de libertad del denominador, ν2, y se denota como: f(F) = (Γ((ν1+ν2)/2) / (Γ(ν1/2) * Γ(ν2/2))) * (ν1/ν2)^(ν1/2) * F^(ν1/2-1) * (1 + (ν1/ν2)*F)^(-(ν1+ν2)/2).</p>


      <h2>Distribución Binomial</h2>

      <iframe src="https://drive.google.com/file/d/1g_PEkdkqmkfmEAheo9kOdT5QMQFfqKcA/preview" width="640" height="480" allow="autoplay"></iframe>



      
      <h2>Regresión lineal</h2>
    <ul>
        <h3>TEMA 5</h3>
        <ul>
                    <li>5.1 Regresión y correlación.</li>
                    
                    <li>5.1.1 Diagrama de dispersión.</li>
                    <li>5.1.2 Regresión lineal simple. </li>
                    <li>5.1.3 Correlación.</li>
                    <li>5.1.4 Determinación y análisis de los coeficientes
                        de correlación y de determinación.</li>
                    <li>5.1.5 Distribución normal bidimensional</li>
                    <li>5.1.6 Intervalos de confianza y pruebas para el
                        coeficiente de correlación</li>
                    <li>5.1.7 Errores de medición  </li>
                    
                    
                    
                </ul>
            </li>
            <h3>Subtemas</h1>
             <ul>
      <strong>5.1 Regresión y correlación. </strong>
      <strong>5.1.1 Diagrama de dispersión.</strong>

      <strong></strong>

      <p>Un diagrama de dispersión es una representación gráfica de la relación entre dos variables. En el diagrama, cada punto representa un par de valores de las variables, permitiendo identificar si existe una relación lineal o de otro tipo entre ellas.</p>

      <strong>5.1.2 Regresión lineal simple:.</strong>

      <strong></strong>

      <p>La regresión lineal simple es un método estadístico que permite modelar la relación lineal entre una variable dependiente (Y) y una variable independiente (X). La ecuación de regresión lineal simple es: Y = a + bX, donde "a" es la intercepción y "b" es la pendiente de la recta de regresión.</p>

      <strong>5.1.3 Correlación:</strong>

      <strong></strong>

      <p>
        La correlación mide el grado de relación lineal entre dos variables. El coeficiente de correlación, denotado como "r", varía entre -1 y 1. Un valor de r = 1 indica una relación lineal perfecta positiva, r = -1 indica una relación lineal perfecta negativa, y r = 0 indica que no hay relación lineal entre las variables.</p>

        <strong>5.1.5 Distribución normal bidimensional:</strong>

        <strong></strong>
  
        <p>
            
La distribución normal bidimensional describe la probabilidad conjunta de dos variables aleatorias X e Y que siguen una distribución normal multivariada. Esta distribución está caracterizada por los parámetros de la media y la matriz de covarianza de las variables.</p>

<strong>5.1.6 Intervalos de confianza y pruebas para el coeficiente de correlación:</strong>

<strong></strong>

<p>
    Se pueden construir intervalos de confianza para el coeficiente de correlación poblacional ρ, y realizar pruebas de hipótesis para determinar si existe una correlación significativa entre las variables.</p>

    <strong> 5.1.7 Errores de medición:</strong>

<strong></strong>

<p>
   
    Los errores de medición pueden afectar la estimación de los parámetros de regresión y correlación. Existen métodos para corregir el efecto de los errores de medición, como el modelo de regresión con errores en las variables.</p>

  
      






<style>



    body {
         font-family: Georgia, serif;
         background-color: #e7f3fe;
         color: #333;
         line-height: 1.6;
         margin: 20px; /* Añadido para mejorar el espacio alrededor del contenido */
     }

     h1 {
         color: #096b63;
         text-align: center;
         margin: 20px 0;
     }

    h2 {
         color: #54a7c8;
         text-align: center;
         margin: 20px 0 10px;
     }

     h3 {
         color: #549dc8;
         margin: 15px 0 5px;
     }

     ul {
         list-style-type: none;
         padding-left: 20px;
     }

     li {
         margin-bottom: 10px;
         color: #3a9197;
     }

     p {
         margin-bottom: 15px;
     }

     ul ul {
         margin-top: 5px;
         margin-bottom: 15px;
     }

     img {
         display: block;
         margin: 10px auto;
         max-width: 100%;
     }

     /* Estilo para los enlaces */
     .enlaces {
         display: flex;
         justify-content: space-between;
         margin-top: 20px;
     }

     .enlaces a {
         padding: 10px 20px;
         background-color: #54b7c8;
         color: rgb(255, 255, 255);
         text-decoration: none;
         border-radius: 5px;
     }

     .enlaces a:hover {
         background-color: #3c6c8c;
     }

 </style>


</html>